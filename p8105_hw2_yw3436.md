Homework 2
================
Yuqi Wang

This is my question for HW2.

``` r
library(tidyverse)
```

    ## ── Attaching packages ───────────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ──────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

First, define a path to the dataset.

``` r
path_to_data = './data/Trash-Wheel-Collection-Totals-8-6-19.xlsx'
```

Read the Mr. Trashwheel dataset.

``` r
trashwheel = 
  read_excel(path = path_to_data,
             sheet = "Mr. Trash Wheel",
             range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = round(sports_balls),
         sports_balls = as.integer(sports_balls))
# the default sheet for read_excel() is the first sheet in the excel.
# if we use round(), the type of the variable will still be double, but if we use as.integer, the type will be integer after transformation.
```

Read 2018 and 2017 precipitation data.

``` r
precip_2018 = 
  read_excel('./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx',
             sheet = "2018 Precipitation",
             skip = 1) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 = 
  read_excel('./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx',
             sheet = "2017 Precipitation",
             skip = 1) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now, combine 2017-2018 precipitation data.

``` r
month_df = tibble(
  month = 1:12,
  month_name = month.name
)

precip_data = 
  bind_rows(precip_2018, precip_2017) #%>% 
  #mutate(month = month.name[month])

left_join(precip_data, month_df, by = 'month')
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2018     1  0.94 January   
    ##  2  2018     2  4.8  February  
    ##  3  2018     3  2.69 March     
    ##  4  2018     4  4.69 April     
    ##  5  2018     5  9.27 May       
    ##  6  2018     6  4.77 June      
    ##  7  2018     7 10.2  July      
    ##  8  2018     8  6.45 August    
    ##  9  2018     9 10.5  September 
    ## 10  2018    10  2.12 October   
    ## # … with 14 more rows

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month and trash collected, including some
specific kinds of trash. There are a total of 344 rows in our final
dataset. Additional data sheets include month precipitation data in 2017
and 2018.

## Problem 2

First, read the data set, clean the names, and select the required
columns. Next, convert the entry variable to a logical variable.

``` r
nyc_transit_df = read.csv('./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv', na.strings = c("","NA")) %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = recode(entry, 'YES' = TRUE, 'NO' = FALSE))
```

Description of the dataset: This data set includes information about the
NYC subway transits. It contains the following variables: ada,
entrance\_type, entry, line, route1, route10, route11, route2, route3,
route4, route5, route6, route7, route8, route9, station\_latitude,
station\_longitude, station\_name, vending. So far, the data has been
imported into R, and the variable names have been cleaned, and the entry
variable was recoded as a logical variable. The size of the data set is
1868 rows x 19 columns.

The data is not tidy because from route1 to route11 we see that the
route information is spread across 11 columns.

Next, answering the three questions:

``` r
# Question 1: distinct stations
station_num = distinct(nyc_transit_df, line, station_name)

# Question 2: ADA compliant stations
ada_num = distinct(nyc_transit_df, line, station_name, ada) %>% 
  filter(ada == TRUE)

# Question 3: proportion of entrances without vending
no_vending_num = nyc_transit_df %>% 
  filter(vending == 'NO', entry == TRUE)
entry_num = nyc_transit_df %>%
  filter(vending == "NO")

no_vending_prop = nrow(no_vending_num)/nrow(entry_num)
```

  - There are 465 distinct stations.
  - There are 84 ADA compliant stations.
  - The proportion of station entrances/exits without vending allow
    entrance is 0.3770492.

Next, separate route name and route number as separate variables.

``` r
nyc_transit_tidy = nyc_transit_df %>% 
  mutate(route8 = as.character(route8), 
        route9 = as.character(route9),
        route10 = as.character(route10),
        route11 = as.character(route11)) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route",
    names_prefix = "route",
    values_to = "route_name"
  )
```

Select distinct station that serves A train

``` r
a_train_serv = nyc_transit_tidy %>% 
  filter(route_name == "A") %>% 
  distinct(line, station_name, ada, .keep_all = TRUE)

a_train_ada = a_train_serv %>% 
  filter(ada == TRUE)
```

There are 60 distinct stations serving A train. Among these stations, 17
are ADA compliant.

## Problem 3

First step: process the pols\_mon data

``` r
pols = read.csv('./data/fivethirtyeight_datasets/pols-month.csv') %>% 
  separate(mon, c("year", "month", "day"), "-") %>% 
  mutate(year = as.integer(year),
         month = as.integer(month),
         day = as.integer(day)) %>% 
  mutate(month = month.name[month]) %>% 
  mutate(president = ifelse(prez_gop == 1, "gop", "dem")) %>% 
  select(-day, -prez_gop, -prez_dem) %>% 
  relocate(year, month, president)
```

Second step: processing the snp data

``` r
snp = read.csv('./data/fivethirtyeight_datasets/snp.csv') %>% 
  separate(date, c("month", "day", "year"), "/") %>% 
  mutate(year = as.integer(year),
         month = as.integer(month),
         day = as.integer(day)) %>% 
  mutate(month = month.name[month]) %>% 
  select(-day) %>% 
  relocate(year, month)
```

Third step: tidying the unemployment data

``` r
unemployment = read.csv('./data/fivethirtyeight_datasets/unemployment.csv') %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment_prop"
  ) %>% 
  relocate(year, month)
```

Join the three data sets together

``` r
join_df = pols %>% 
  left_join(snp, by = c('year', 'month')) %>% 
  left_join(unemployment, by = c('year', 'month'))
```

Description of the dataset:

  - *pols*: This data set contains 9 variables, gov\_dem, gov\_gop,
    month, president, rep\_dem, rep\_gop, sen\_dem, sen\_gop, year,
    which are related to the the number of national politicians who are
    democratic or republican during 1947 and 2015, and there are 822
    observations in the dataset.

  - *snp*: This data set contains 3 variables, close, month, year, which
    are related to Standard & Poor’s stock market index (S\&P) during
    1950 and 2015, and there are 787 observations in the dataset.

  - *unemployment*: This data set contains 3 variables, month,
    unemployment\_prop, year, which represent the percentage of
    unemployment during 1948 and 2015, and there are 816 observations in
    the dataset.

  - **resulting data**: The joined dataframe contains 822 observations
    and 11 variables to show the general information about politics from
    1947 to 2015. The variables include close, gov\_dem, gov\_gop,
    month, president, rep\_dem, rep\_gop, sen\_dem, sen\_gop,
    unemployment\_prop, year.
